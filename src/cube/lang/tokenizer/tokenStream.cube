use cube.lang
use cube.lang.parser.syntaxError
use cube.lang.syntax
use cube.text

define tokenStream
  function create(tokenizer as tokenizer) = me.tokenizer = tokenizer

  function next as token
    fill(0)
    output buffer.remove(0)
  end

  function expect(s as symbol) as token
    var t as token = next
    if t.isSymbol(s) then output t
    error expected(s, t)
  end

  function expect(k as keyword) as token
    var t as token = next
    if t.isKeyword(k) then output t
    error expected(k, t)
  end

  function read(s as symbol) as token
    var q0 as token = peek(0)
    if not q0.isSymbol(s) then output null
    next
    output q0
  end

  function peek(n as int) as token
    fill(n)
    output buffer.get(n)
  end

  shared
    function tokenStream(text as string) = new tokenStream(new tokenizer(text))
  end

  internal
    let buffer = new list[token]
    var tokenizer as tokenizer

    function fill(n as int) =
      while buffer.size <= n
        var o as token = null

        if tokenizer.next then do
          var text as string = tokenizer.tokenText
          var t as nodeType = tokenizer.tokenType
          var p as textPosition = tokenizer.tokenPosition

          match t
            when Symbol then o = new symbolToken(tokenizer.symbol, text, p)
            when Keyword then o = new keywordToken(tokenizer.keyword, text, p)
            when Identifier then o = new identifierToken(text, p)
            when Number or ConstantKeyword or QuotedString then o = new constantToken(t, text, p)
            else error new unsupportedOperationException(t.toString)
          end
        end

        buffer.add(o)
      end
  end
end