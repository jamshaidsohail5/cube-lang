use cube.lang
use cube.lang.cst
use cube.lang.parser.syntaxError

define tokenStream
  function create(tokenizer as tokenizer) = me.tokenizer = tokenizer

  function next as token
    fill(0)
    output buffer.remove(0)
  end

  function expect(s as symbol) as token
    var t as token = next
    if t.isSymbol(s) then output t
    error expected(s, t)
  end

  function expect(k as keyword) as token
    var t as token = next
    if t.isKeyword(k) then output t
    error expected(k, t)
  end

  function read(s as symbol) as token
    var q0 as token = peek(0)
    if not q0.isSymbol(s) then output null
    next
    output q0
  end

  function peek(n as int) as token
    fill(n)
    output buffer.get(n)
  end

  shared
    function tokenStream(text as string) = new tokenStream(new tokenizer(text))
  end

  internal
    let buffer = new list[token]
    var tokenizer as tokenizer

    function fill(n as int) =
      while buffer.size <= n
        var p as token = null

        if tokenizer.next then do
          var text as string = tokenizer.tokenText
          var t as cstNodeType = tokenizer.tokenType

          match t
            when SYMBOL then p = new symbolToken(tokenizer.symbol, text)
            when KEYWORD then p = new keywordToken(tokenizer.keyword, text)
            when IDENTIFIER then p = new identifierToken(text)
            when NUMBER or CONSTANT_KEYWORD then p = new constantToken(t, text)
            else error new unsupportedOperationException(t.toString)
          end
        end

        buffer.add(p)
      end
  end
end